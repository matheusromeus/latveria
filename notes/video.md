I need to be real with y'all. It's been pretty hard to defend Nex.js over the last 2 years. There's a lot I love about it, but there have been a lot of things that rightfully people have been upset about. There's even a few that I'm personally very burned about. Don't get me started on the Turbo Pack stuff. It's it's been a lot. That said, there's been a significant course correction over the last few months, and we're starting to see it really come out with the latest version of Next 15.3. There are a ton of useful changes both within the next 153 release itself and within the things going on around it. All of which are worth talking about and better understanding. So whether or not you're an XJS dev, I think this will be useful just to better understand where the market is going and how Versel is course correcting. If you are an XJS dev, this is absolutely going to be an essential watch. But as you guys know, Verscell

what makes NEX53 so special? First and foremost, it is the build side of things because Turboac finally now supports builds in alpha. That means you probably shouldn't be using this for production just yet, but they've been using it for production already at Versell, which is really, really cool to see. They share some numbers underneath here. First off though, over half of dev sessions on Next 15 are already using TurboAC, so they've had support in dev for a while.  
All the projects I work in use Turboac.  
It is a massive difference. You go from waiting minutes for the dev environment to spin up to seconds and updates with the hot reloading literally happen pretty much instantaneously, like under 100 milliseconds most of the time. It's so much better and I couldn't work on a project the size of T3 chat without Turboac. It would just be miserable. The alternative would be VIT in the VT ecosystem which goes similarly fast but that doesn't necessarily carry you through things like the server and client side behaviors that Webpack and Turbopac currently allow. I still have to find a full stack vit framework that feels as complete in it implementation on both server and client side. That's why I find myself in next even if I'm throwing away a bunch of the built-in stuff. Their clear split and path for both the server and client side as well as the relationship between them is still very convenient. Waku is so far it is hilarious but thank you for mentioning it. Waku is really cool as a server component demo. It is not cool as a full stack backend plus fronted in one codebas thing. And Nux is cool but not even close.  
Anyways, Verscell has maintained this are we turbo yet page for a while now.  
Previously, it would default to development where they had a set of tests that were needed for dev environments to work properly for nextdev using Turopac instead of Webpack. And there is just one random error here left. The rest are all handled. Now, the site defaults to production where it's still not quite there because they have to pass 8,095 tests, but they are very, very close. They have 57 left and most projects should be able to at least build using this. Very, very cool to see. And the results going to be way better build times since this can take more advantage of multi-core multi-threading because Turopac was written in Rust and it was written to use these threads and to use your processor better. Four cores you'll see a 28% speed improvement. 16 cores you'll see 60% and on a 30 core probably not a desktop machine at your place but some worker in the cloud 83% faster builds.  
That's huge. Finally having scaling with our threads fundamentally changes the build performance that we should expect using TurboAC in building our next.js projects. This is not the only change to build though. Historically the build tools have just kind of been part of Nex.js directly. One of the main reasons Nex came out is so we would have to stop fussing with our Webpack configs and that's been great. But now there's another alternative for Webpack RSpack.  
And as of this release there is now officially community support for RSpack instead. So if you want to use other options that aren't fully part of the versel ecosystem, you can. Now this is huge. I never thought I would see the day that the deep tie that Nex.js has to Webpack and now TurboAC would be broken at all to allow other options, but Versel actually directly reached out to the RSpack team and I've been in touch with them for a bit about this stuff.  
They were so hyped because no one expected it. It really shows this change in the philosophy on the next team.  
Instead of just being an all-in-one set of pieces that you use if you need them and you throw away if you don't, it's becoming more modular where given parts can use the thing Verscell provides or the thing someone else provides, which is why this other announcement with the deployment adapters API is such a big deal. This isn't technically part of the 153 release, but it was clearly meant to be aligned with it. The goal with the deployment adapters API is to allow for Nex to be deployed anywhere, including serverless platforms with custom requirements. This is an important distinction because right now without any of these changes, you can absolutely deploy Nex.js wherever you want. The catch is you probably can only really deploy it in a Docker container because that's how you run Node applications.  
Verscel has built a really powerful infrastructure to split different parts of Next into different environments. So it's not just running in a Docker container. It's running compute in one place for your API calls and for your page gen. It's running a CDN somewhere else so it can serve static assets. It's running edge compute for middleware that redirects your requests. That separation is not fun to build yourself and it is deeply baked into Versell. And that's why Next is so nice on Versel, not because they made it hard to deploy elsewhere. There is no other framework that can be deployed to any other place that provides the level of integration that Nex does on Verscell. That's not because they built Nex to work that way.  
It's because Verscell allows it. And there are other frameworks too like obviously spelt which is built at Verscell now. But even frameworks like solid start I don't have a good experience deploying other places and the functionality is not as deeply baked especially the hybrid of static content semi-static content cache on the CDN and dynamic content. The integration there is really really hard especially when compute isn't just always running with a dedicated server. So despite the fact that you can absolutely run next on a dedicated server with no issues, a lot of cool functionality in modern X.js like incremental static revalidation, caching, middleware rewrites, and all these other useful pieces were not trivial to implement in serverless environments. The goal of the deployment adapters API is to make it easier for other platforms like Netlefi to support deploying Nex.js. JS due to their custom requirements. That is a huge change.  
It's also worth noting this is an RFC.  
It's a request for comments. The Versel team and Le in particular really want to hear from the community to make sure that if they do this, they get it right.  
They want to learn lessons from projects like Open Next to make sure that Nex.js can be deployed well regardless of which environment you want to deploy it to.  
And limitations won't be in the integration between Next and the environment. It'll be the limitations of the environment itself. It is also worth noting that the existing build output API that is the thing you build to to ship on Verscell and take advantage of all of this infra already is open and is a thing anyone can build integrations with. It'd be as far as I understand totally viable to port the Verscell build output like format to run on something like Netlefi and then you can just build it the next Verscell way and deploy it on your stuff. But different services have different expectations and if they don't perfectly align with that build output API, they're screwed. Which is why they're proposing changing the build output structure in order to make it easier for their competition to host Nex apps. That's kind of crazy. Think about this for a second. Like logistically speaking, Burcell is trying so hard to fix this reputation damage that they are spending a lot of money and effort and time and smart people's energy to make the build output of their like main framework harder to maintain internally for Versell for their product but also way easier in general to deploy. This is a massive undertaking to make life easier for their competition because they think that is important right now due to the fact that people have been harassing them about this stuff for so long. I still have the hot take that Verscell did not really do anything wrong in terms of support for other platforms, but the features they introduced were so cool and compelling, but so tied to specific infrastructure implementations that it optically looked bad that these cool new features were hard to do or not even viable to do on other hosting platforms. I also suspect that there are fewer and fewer of those groundbreaking infrastructure features coming to next in the future. So now is a good time to make this cut because I do not think we'll ever have another server component moment with Nex. I don't think we'll have another app router moment with Nex. The closest thing we'll have is the Turbo Pack moment when it's like actually ready.  
The question from Gabriel here is will this slow down the pace of innovation of Nex in the future. If the intent was to maintain the current pace, yes, absolutely. But I think the pace has inherently slowed down in terms of innovating within Nex.js for a ton of reasons. Be it the community outcry, the focus on AI stuff instead, the difficulty in integrating these things, the focus on making new infra primitives on Verscell directly instead. All of these things mean I would expect there to be much less innovation within the next.js framework directly, which means it's okay to take a hit, so to speak, in your ability to iterate by changing the APIs these ways purely to help competition. CHGBT now refers 10% of versel signups which is accelerating.  
Yeah, that's you see where they are going and adding more and more features to Nex.js is no longer the strategy for the next team and for versell the future isn't more features in next. The future is infra to better support the new types of apps and new types of developers who are building. The next is definitely more open. The way I'm thinking about this is weird. That's why I want to write it all out. For a long time, my favorite way to try new tech has been Versel. It's just been very reliable.  
The server primitives and the cool things you can do with it have been really, really killer. I've told this story a few times, but I got into Verscell as a front-end dev that had done a lot of backend in the past, but had mostly moved to front end that was working at a small startup with a really, really shitty backend team that was blocking me constantly. And I needed a few endpoints that they just weren't building for me that would hit an endpoint that we had like a specific API key for to get data that users needed.  
And I discovered a really cool thing, the slash API directory.  
My app was a React app built funny enough with Snowpack at the time and then I ported over to Vit when it got better. It's the last thing I did before I left this company. But with Verscell, if I deployed it there, I could add a directory named API, put a random TypeScript function in it, and all of a sudden that would automatically deploy to a serverless node environment that I could then hit from my app. That was magical. That was a huge, oh I can do what moment for me. Even though this was very much I ran the front end for this team, I was able to quickly stub out a specific backend function for a specific thing. This ended up being my introduction to the like backend for frontend pattern and it fully rewired my brain. Huge huge moment for me that led to the T3 stack existing was the discovery of this directory not with next just as a feature on Verscell directly. So as I've said before I got into Verscell way before I got into Nex.js. I thought it was an unnecessary abstraction because I already knew how to do Webpack configs and I had moved to V at that point. So the API directory and the ability to just deploy a Versell function by writing some TypeScript or Python or whatever else absolutely destroyed my brain. This ended up being the reason Verscell was my platform of choice. When I tried any new framework, be it an update to Next, a new flavor of Remix, Solid Start, spelt, anything else. Versel was where I deployed it because I knew Versel's infra well. I knew what it was capable of and it was the easiest way for me to quickly see the differences between these tools and technologies. I would regularly publish different benchmarks in tools like Astro and spelt and solid and I would deploy all of them on Verscell because it was the easiest way to test. In fact, there was a while where you couldn't run Next on Edge. So to test Verscell's edge network, I was deploying Astro on it because again Verscell was the best set of primitives for me to play with a new tool or technology and I found myself using them all the time in that way.  
Other platforms have caught up in meaningful ways. Netleifi has their own really cool stuff nowadays too, especially on the queuing side. They are killing it over there. But I still find myself reaching to Verscell simply because it's the one I'm familiar with and I understand the relationship between their primitives really well. So I think this is what's going to change a bit. Not that I won't like using Verscell, but almost the opposite. I use Verscell to test new frameworks. When a new framework comes out, the first thing I try to do is deploy it on Versell. I see how that goes. What I think's going to happen now is hopefully I can use Nex.js to test new providers. The same way I use Verscell to try out the new spelt version, I see a future where I use Nex.js to try out the new Cloudflare worker stuff. That would be very, very exciting for me. That would be a huge exciting opportunity to test out the performance characteristics, cost benefit of different providers and all of the other things you need to know about a given provider when you're making decisions for your business. all the things I like to talk about, I like to consult about, I like to help other businesses with the things that you guys are all here to learn from me. It will be significantly easier for me to test out the new stuff they just shipped in Cloudflare like shipw week if I could deploy next on it super reliably with an existing open standard for doing it. I see a very exciting future where the same way I use for test frameworks, I can use Next to test other competitors.  
And my guess is they see this future too. They know that their infra especially things like the fluid compute stuff are far ahead enough that if you can deploy next with all of its features other places you'll still see a better experience on Verscell. I think it would make a lot of sense for them. There are a couple other important things in this release. Client instrumentation is a very nice change. Now there's a specific single spot where you can introduce instrumentation for your client. So things like sentry and highlight are way easier than ever to add tracking for.  
Also generic error handling and stuff like that. really nice to see. They already had this for server side, but having it client side too, it's really cool. Also means now more than ever, I think there's an opportunity for somebody to come out with a minimal alternative to a product like Sentry that's also very AI integrated and ready and kill. So if you are building that and are interested in chatting, my DMs are open on Twitter. Would love to hear more. The the future is now and now is ready. Hell, I've been ready for like five years for a minimal sentry alternative. So please somebody make it happen. Oh, I didn't see this. New navigation hooks to enhance client side routing capabilities in Nex 153, so you can develop localized loading states to implement complex controls like navigation cancel on navigate is a very useful addition to the link component.  
The use link status client component hook returns a pending boolean that indicates whether navigation is in progress. That is so good. That's so good. Custom load stages got a 100 times better. I'm hyped on that. the these are the types of changes that make it so I could theoretically actually move off of React Router for T3 chat. I'm not going to do it, but it's a lot more viable than it was prior. They made the plugin for TypeScript much better. Cool to see.  
I barely use it. I always forget about it. And I'm not using enough like next internal stuff that it's super useful to me anymore. But I really want to test out these build speed changes. Let's see how fast I can build T3 chat with it.  
Pull latest. Kill my dev environment.  
I'm a little behind on next versions, so forgive me. We're going to do a run build on this. See how long it takes on the current 1516 that we are on. Build failed because of Webpack errors. Joy, what did I forget? Attempt two. So, building on my maxed out M2 Pro takes about 50 seconds. Good to know. 28 total. I hate how these numbers are split, but it it felt like 50 seconds.  
This is a build without Turboac to be clear. Just doing another build on the latest version to make sure. Well, still almost exactly the same amount of time without using Turboac. And now for the moment of truth. The Turbo Pack build. 11 seconds. That felt hilariously faster. Turns out this number does matter. This is CPU time because holy that was significantly better.  
What I really want to see though is how much faster is this on Verscell's infra like actually building Theo next turbo version bump. Also fun thing if anybody wants to build this um there is no good command to create a pull request for where I am like the GHPR create is super super comically slow. The closest thing I've been able to find is I use lazy git. I press three and then I press O to open up the tab for making a pull request. It's by far the fastest because it hardcodes the URL and I've been unable to write a custom command to do it because lazy git won't take arguments to then trigger this. So Zodia can make like a super simple oneline thing. So I don't have to open up lazy every time I just want to open a PR because I do that. It's like instal LG30 because it's the fastest way by far to do it and it's annoying. I can never tell if you're trolling at any point, dev. Add a GitHub MCP server and let cursor do it. The problem is the latency. Adding three to 10 round trips does not make it better.  
All I want is to automatically open the URL with the right stuff once I've pushed the branch. This one is not fast.  
This command is very slow. This is what I wanted to do, but the GHPR create does like four round trips before it can actually generate it. And even better, it will fail if your content for your description is too big, which happens automatically if you have enough commits. So, it's very fun. And by fun, I mean entirely broken. Oh, the build's already done. Okay, let's check out deployment speed for that. Not much better. Did I not I I committed the turbo change, didn't I? Get status. I did. Oh, that's a good call out. I didn't know this. Turbopac currently always builds production source maps for the browser. This will include project source code if deployed to production.  
Is that your bundle size may be different from next build with Webpack.  
This will be improved as we work towards stability. This build is without discaching. Subsequent builds will become faster when disc caching becomes available. When comparing output to Webpack builds, make sure to first clear the next.js cache by deleting the next directory. Okay. Why was this not more faster though?  
Like we have builds that are faster than that already. If I go make like a useless change here, I'll change the 404. Let's see how long this build takes.  
Yeah, chat is suspecting that the slowness is because it had to download all the packages again because I changed package lock, which makes sense. We will see how it performs now that that part at least should theoretically be cached. Yep, we're we're over what our shortest builds normally look like already. Yeah, the the compilation step there still took over a minute.  
We scroll back up here to uh creating optimized production build like when it started 3253 gave some warnings and then it was 3340 it was done. So almost a minute of just compile it says 46 seconds. Yeah.  
So, similarly, funny enough to when I tried showing off the roll down performance theoretical wins, I'm just not seeing it much. Like, if I deploy a brand new V app, the build time will be like 15 seconds, but a decent sized next app still in the 1 and a half to two minute range. But like our production build, our last one just was adding a missing icon 57 seconds.  
It's not much faster here. My guess is that the boxes that the builds are running on are single core because historically multi-core has not benefited the build performance. And I would hope that they're going to buff up the build boxes alongside this change.  
Maybe give the multiple cores. I I was hoping for more there though. Let's see if the preview build works, though.  
captures will likely fail because I have them set up for this URL. Yep, knew that. But everything works in the build. That's cool as hell.  
Seems like it's productionish ready, but I was hoping for a bigger PF win. If you run your own build pipeline, this could be absolutely massive, but the deployment pipeline is just not seeing a meaningful change yet. Sadly, I was very hopeful it would, but on my machine again where it has actual multiple cores to use for it, it's comically faster.  
6.3 seconds for the compilation step for the entire project is hilarious when previously if I unturbo it quick time pm run build. So here build took over twice as long total. about the interesting number here. Compiled successfully in 15 seconds versus 6 seconds. 6.3 15.0.  
That's a huge difference and it's one I'm very excited about, but that's the only number that could theoretically improve here. Another fun thing I'm just curious about, uh, what's the HTOP alternative everybody tells me to use? I have it installed. BTOP. That's what I thought. Thank you guys. Cool. So, running once again, not using TurboAC.  
You'll see my utilization here. And mind you, I don't stream from the computer that I am using here. I have a separate Windows rig over HDMI. So, the only thing being used here is whatever apps I'm using, plus this compilation. You see that like my cores aren't really being utilized a whole lot here. I'm guessing most of them are being more used by the Thunderbolt port and my browser than are being used by this compilation. And if I kill the next and run it again because I forgot to, we'll see one of my cores got utilized up to like 60%. Yeah, that one core. That's almost certainly the one running this.  
And now it's doing the bundling for the routes, which it can split already. And now I'm guessing it's done. I know it's close. Yeah, but you can see very clearly most of the work goes on on just one single core. Now that it's done, we can see wasn't very fast. If I go back and turn back on turbo pack and now we see here hopefully.  
Yeah, see that? That's the difference.  
All of my cores are being used. Oh, my terminal's not wide enough. God damn it.  
I can't hide my face. I'm just going to move this. It's already done. Let's time pun build. Cool. Here you can see all of my cores are being hammered. It is fully taking advantage of my system for that six-second burst and then it's done.  
Then it all throttles down. But that's the first time I've had a Nex.js JavaScript build use all of the cores on my machine. I would bet that the amount of total compute being used is probably higher, but the result is a much faster build, which is really cool. So yeah, I think that should hopefully help you understand the performance characteristics and how this is better and worse and what the differences are.  
Hopefully you also now see why I'm excited about the future of Nex.js as a platform to support every different place you might want to deploy your apps. I'm hyped. This seems like the right call for Nex.js. And it also plays into an idea that I've been pushing more and more, which is that I don't think the future of frameworks is going to be endless new features and syntax and all of those things because the AI has already been trained on the current everything we use. So my guess is that over time we'll see more and more releases like this that are focused less on adding new APIs and functionality and more on improving what we already have so that existing output, existing code, existing AI tools and models, generating new projects can all benefit without having to use new syntax. Are your feelings about next changing after this release? Let me know in the comments.